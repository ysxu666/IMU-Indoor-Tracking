# Overview
In this project,You can utilize Machine Learning or Deep Learning for IMU-based Robot Indoor Tracking, including the model design, training strategy, etc.

# Description
Indoor tracking is a crucial topic in our daily lives, whether it is for pedestrians or robots. Considering the scenario that you go to a completely new shopping mall and get lost in it, an indoor tracking or indoor navigation system would help you a lot. Among all of these indoor tracking methods, inertial measurement unit (IMU) attracts much attention. With accelerations, gyroscopes, and magnetometers, IMU can record the variation of the movement and thus map to the moving trajectory of the object.

In this personal project, we will focus on IMU-based indoor tracking for wheeled robots. More details will be given below.

## 1. Dataset Description
The dataset contains four parts: Training Set, Validation Set, Test Seen Set, and Test Unseen Set. We will give you the raw data and ground truth of the Training Set and Validation Set for training the model. Only raw data from the Test Seen Set and Test Unseen Set are for the model evaluation. Training Set, Validation Set, and Test Seen Set are collected in the office:
![image](https://github.com/ysxu666/IMU-Indoor-Tracking/assets/70496853/b9fb91ef-57ca-4b59-a26e-aaf16cf511e6)
And Test Unseen Set is collected in two large rooms:
Each sequence of data lasts 3-6 minutes. The ratio of Training Set, Validation Set, Test Seen Set, and Test Unseen Set is 13:2:3:2.

## 2. Data Format
The data is collected by Google Tango Phone. The raw data is stored in the format of 'hdf5'. Each file contains two parts: synced and pose. synced contains the raw data of IMU, and pose contains the ground truth of the robot's pose. The data format of synced is as follows:

synced
├── gyro (gyroscope in body frame)
├── acce (acceleration in body frame)
├── magnet (magnetometer measured in body frame)
├── linacce (acceleration without gravity in body frame)
├── gravity (gravity in body frame)
├── game_rv (game rotation vector)
├── rv (rotation vector)
├── time (time stamp)

The data format of pose is as follows:
pose
├── time (time stamp)
├── tango_pos (position of the robot in navigation frame)
├── tango_ori (orientation of the robot in navigation frame)

You can refer to the following links for more details about game rotation vector and rotation vector. In short, both game rotation vector and rotation vector can convert the data from the body frame to the navigation frame. The difference is that game rotation vector is calculated by the gyroscope and accelerometer, while rotation vector is calculated by the gyroscope, accelerometer, and magnetometer.

## 3. Problem Formulation
The problem is formulated as a regression problem. Given the raw data of IMU, we want to predict the robot's moving trajectory. As the raw data generated by IMU is in the body frame, which cannot be mapped to the moving trajectory directly, we need to convert the raw data from the body frame to the navigation frame. You can read the supplementary material for more detail about IMU data and the conversion from the body frame to navigation frame.

## 4. System Workflow
To help you better get started with the project, we provide a baseline model for you. The baseline model is a simple LSTM model. You can refer to the following figure for the system workflow:
![image](https://github.com/ysxu666/IMU-Indoor-Tracking/assets/70496853/ba2c0cc7-a729-41e7-9857-4f90ff13aae5)
The workflow contains two parts, training and testing. In the training stage, we will first separate raw IMU data into multiple sequences with the same length. After that, the preprocessing methods are implemented, including noise filtering, coordinate transformation (from body frame to navigation frame), and data augmentation (random rotation on the floor plane). Then, the preprocessed data will be fed into the LSTM model for training. The csum in the loss function represents the cumulative sum of the velocity, which accounts for the position. In the testing stage, we didn't separate the raw IMU data into multiple sequences. Instead, we feed the whole sequence into the LSTM model and predict the trajectory. And we only apply the noise filtering and coordinate transformation in the testing stage. To measure the performance of the baseline model, we use four metrics: Absolute Trajectory Error (ATE), Relative Trajectory Error (RTE), Position Drift Error (PDE), and Absolute Yaw Error (AYE). You can refer to the evaluation part for more detail about these metrics.
